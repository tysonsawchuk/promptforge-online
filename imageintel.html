<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ImageIntel Pro Visor — M1 Test (PromptForge)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
  <meta name="description" content="PromptForge — ImageIntel Pro Visor (M1): on-device photo deconstructor with face mesh, pose, segmentation overlays, prompt export, and JSON v4.">
  <link rel="canonical" href="https://promptforge.online/imageintel.html">
  <meta property="og:title" content="ImageIntel Pro Visor — M1 Test">
  <meta property="og:description" content="On-device photo deconstructor: overlays + SFW prompt + JSON v4.">
  <meta property="og:type" content="website">
  <meta property="og:image" content="/assets/og/imageintel.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="theme-color" content="#0ef">
  <style>
    :root{
      --bg:#0b0d12; --panel:#121622; --ink:#dbe5ff; --muted:#8aa0c2;
      --aqua:#0ef; --mag:#ff4bd6; --lime:#b4ff4b; --red:#ff5e7a; --amber:#ffb84b;
      --grid:#1a2032; --hl:rgba(14,255,255,.1);
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0; background:
        radial-gradient(1200px 800px at 20% -10%, #10162a 0%, #0b0d12 60%, #0b0d12 100%);
      color:var(--ink); font:14px/1.5 system-ui,Segoe UI,Roboto,Inter,Ubuntu,"Helvetica Neue",Arial;
      -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale;
    }
    header{
      padding:18px 16px; border-bottom:1px solid #111724;
      background:linear-gradient(180deg, rgba(14,255,255,.05), transparent 40%);
    }
    header .title{
      font-weight:700; letter-spacing:.5px; display:flex; gap:10px; align-items:center;
    }
    header .badge{
      font-size:12px; padding:2px 8px; border:1px solid var(--aqua); color:var(--aqua);
      border-radius:999px; background:rgba(14,255,255,.08);
    }
    main{max-width:1200px; margin:0 auto; padding:16px; display:grid; gap:16px}
    .grid{display:grid; grid-template-columns: 1.2fr .8fr; gap:16px}
    @media (max-width:1100px){.grid{grid-template-columns:1fr}}
    .card{
      background:linear-gradient(180deg, rgba(255,255,255,.03), rgba(255,255,255,.01));
      border:1px solid #141b2a; border-radius:14px; overflow:hidden; position:relative;
      box-shadow:0 10px 40px rgba(0,0,0,.25), inset 0 1px 0 rgba(255,255,255,.04);
    }
    .card h3{margin:0; padding:12px 14px; border-bottom:1px solid #141b2a; background:#0f1524; font-size:13px; letter-spacing:.6px; text-transform:uppercase; color:#bfe9ff}
    .card .body{padding:14px; display:grid; gap:12px}
    .row{display:flex; flex-wrap:wrap; gap:10px; align-items:center}
    .btn{
      background:#0f1524; color:#dff7ff; border:1px solid #1a263f; padding:10px 12px; border-radius:10px;
      cursor:pointer; transition:.2s ease; font-weight:600; letter-spacing:.2px;
    }
    .btn:hover{border-color:#25406f; box-shadow:0 0 0 2px rgba(14,255,255,.15) inset}
    .btn.primary{background:linear-gradient(180deg,#0fe,#09c8f0); color:#001318; border:none}
    .btn.warning{border-color:#3a1a2b; background:linear-gradient(180deg,#2a0f1f,#1a0a14); color:#ffcce8}
    .btn.ghost{background:transparent; border-color:#2a344f}
    .toggle{display:flex; gap:10px}
    .toggle label{
      background:#0f1524; border:1px solid #1a263f; border-radius:999px; padding:8px 10px; display:flex; gap:8px; align-items:center; cursor:pointer;
    }
    .toggle input{accent-color:var(--aqua)}
    .sl{display:grid; gap:4px; min-width:200px}
    .sl input[type=range]{width:100%}
    .stageWrap{padding:12px; background:linear-gradient(180deg,#0b101c,#070a12); border:1px solid #121a2c; border-radius:12px}
    .stage{
      position:relative; width:100%; aspect-ratio: 16/10; background:#0a0e18;
      border:1px solid #121a2c; border-radius:10px; overflow:hidden;
    }
    .stage img{position:absolute; inset:0; width:100%; height:100%; object-fit:contain; image-rendering:auto}
    canvas.overlay{position:absolute; inset:0; width:100%; height:100%; pointer-events:none}
    .tabbar{display:flex; gap:8px; border-bottom:1px solid #141b2a; padding:0 12px 8px}
    .tabbar .tab{padding:8px 10px; cursor:pointer; border-radius:8px; color:#bfe9ff}
    .tabbar .tab.active{background:rgba(14,255,255,.12); color:#001318; border:1px solid rgba(14,255,255,.3)}
    .panel{display:none; padding:12px}
    .panel.active{display:block}
    textarea.code{width:100%; min-height:160px; font:12px/1.45 ui-monospace,SFMono-Regular,Consolas,Monaco,"Liberation Mono"; color:#dbe5ff; background:#0c111d; border:1px solid #16213a; border-radius:10px; padding:10px}
    .diag{font:12px/1.4 ui-monospace,Consolas,Menlo,monospace; background:#090e19; color:#bde1ff; border:1px solid #16213a; border-radius:10px; padding:10px; white-space:pre-wrap; max-height:260px; overflow:auto}
    .matrix{display:grid; grid-template-columns: auto 1fr auto; gap:6px 10px; align-items:center; font:12px/1.4 ui-monospace,monospace}
    .ok{color:var(--lime)} .bad{color:var(--red)} .warn{color:var(--amber)} .muted{color:var(--muted)}
    .chip{padding:2px 8px; border-radius:999px; border:1px solid #203255; background:#0e1424; color:#bde1ff; font-size:12px}
    .gauge{height:6px; background:#0d1322; border:1px solid #16213a; border-radius:999px; overflow:hidden}
    .gauge>span{display:block; height:100%; background:linear-gradient(90deg, var(--aqua), #9af); width:0%}
    .kbd{font:11px ui-monospace,monospace; background:#0c111d; border:1px solid #16213a; padding:2px 6px; border-radius:6px}
    .hint{color:#8aa0c2; font-size:12px}
  </style>
</head>
<body>
  <header>
    <div class="title">IMAGEINTEL PRO VISOR <span class="badge">M1 TEST • OFFLINE</span></div>
    <div class="hint">Goal: jaw-dropping overlays + prompt/JSON export. Primary: MediaPipe; Fallback: Human; Minimal: face-api/MoveNet.</div>
  </header>

  <main>
    <div class="grid">
      <section class="card">
        <h3>Step 1 — Load</h3>
        <div class="body">
          <div class="row">
            <input id="file" type="file" accept="image/*" hidden>
            <button class="btn" id="choose">Choose Image</button>
            <button class="btn" id="demo">Use Demo Photo</button>
            <button class="btn ghost" id="selftest">Self-Test</button>
            <span id="engineChip" class="chip">engine: <span id="engineName" class="muted">none</span></span>
          </div>
          <div class="stageWrap">
            <div class="stage" id="stage">
              <img id="src" alt="">
              <canvas id="cFace" class="overlay"></canvas>
              <canvas id="cPose" class="overlay"></canvas>
              <canvas id="cSeg" class="overlay"></canvas>
            </div>
          </div>
          <div class="row">
            <div class="sl">
              <label>Detail <span id="detailVal" class="muted">1.0</span></label>
              <input id="detail" type="range" min="0.6" max="1.6" step="0.1" value="1.0">
            </div>
            <div class="sl">
              <label>Accuracy <span id="accVal" class="muted">1 (medium)</span></label>
              <input id="acc" type="range" min="0" max="2" step="1" value="1">
            </div>
            <div class="toggle" role="group" aria-label="Overlay toggles">
              <label><input id="tgFace" type="checkbox" checked> Face</label>
              <label><input id="tgPose" type="checkbox" checked> Pose</label>
              <label><input id="tgSeg" type="checkbox" checked> Segments</label>
              <label><input id="tgObj" type="checkbox"> Objects</label>
            </div>
          </div>
        </div>
      </section>

      <section class="card">
        <h3>Step 2 — Analyze & Overlay</h3>
        <div class="body">
          <div class="row">
            <button class="btn primary" id="analyze">Preview Overlay</button>
            <button class="btn warning" id="clear">Clear Overlays</button>
            <span class="kbd">Tip: run <b>Self-Test</b> first to confirm local model paths.</span>
          </div>
          <div class="row">
            <div style="min-width:220px">
              <div>Init Time</div>
              <div class="gauge"><span id="gInit"></span></div>
            </div>
            <div style="min-width:220px">
              <div>Analyze Time</div>
              <div class="gauge"><span id="gRun"></span></div>
            </div>
            <div style="min-width:220px">
              <div>FPS (phase)</div>
              <div class="gauge"><span id="gFps"></span></div>
            </div>
          </div>
        </div>
      </section>
    </div>

    <section class="card">
      <h3>Step 3 — Results</h3>
      <div class="tabbar">
        <div class="tab active" data-tab="prompt">SFW Prompt</div>
        <div class="tab" data-tab="json">JSON v4</div>
        <div class="tab" data-tab="diag">Diagnostics</div>
      </div>
      <div class="panel active" id="panel-prompt">
        <div class="body">
          <div class="row">
            <button class="btn" id="copyPrompt">Copy Prompt</button>
            <button class="btn ghost" id="copyNeg">Copy Negative</button>
          </div>
          <textarea id="promptOut" class="code" spellcheck="false" placeholder="Prompt appears here after Analyze…"></textarea>
          <div class="hint">Accuracy levels: 0=tight, 1=medium, 2=rich. Negative list stays SFW in M1.</div>
        </div>
      </div>
      <div class="panel" id="panel-json">
        <div class="body">
          <div class="row">
            <button class="btn" id="downloadJson">Download JSON</button>
          </div>
          <textarea id="jsonOut" class="code" spellcheck="false" placeholder="{ JSON v4 appears here… }"></textarea>
        </div>
      </div>
      <div class="panel" id="panel-diag">
        <div class="body">
          <div class="diag" id="diag">Ready. Run Self-Test to verify assets.</div>
        </div>
      </div>
    </section>
  </main>

  <script>
  /* =========================
     CONFIG — ASSET PATHS
     ========================= */
  const ASSETS = {
    demo: "/assets/demo.jpg", // Replace with a local demo image to stay 100% offline
    mediapipe: {
      script: "/vendor/mediapipe/tasks-vision.js",
      wasmDir: "/vendor/mediapipe/wasm/", // directory that contains *.wasm/*.wasm.js
      face: "/vendor/mediapipe/face_landmarker.task",
      pose: "/vendor/mediapipe/pose_landmarker_full.task",
      seg:  "/vendor/mediapipe/selfie_segmentation.tflite" // or a .task people-multiclass if you prefer
    },
    human: {
      script: "/vendor/human/human.js",
      // If your human build needs models folder, add it here and ensure same-origin:
      modelsDir: "/vendor/human/models/" // optional
    },
    minimal: {
      faceApi: "/vendor/faceapi/face-api.min.js",
      weightsDir: "/vendor/faceapi/weights/",
      movenet: "/models/movenet_lightning.json" // + .bin shards nearby
    }
  };

  /* =========================
     STATE
     ========================= */
  const st = {
    img: null, bmp: null, exifFixed: null,
    engine: "none", // mediapipe|human|minimal|none
    enginesAvailable: [],
    results: null, // unified results
    timings: { initMs:0, analyzeMs:0, fps:0 },
    dpr: Math.max(1, window.devicePixelRatio || 1),
    toggles: { face:true, pose:true, seg:true, obj:false },
    detail: 1.0,
    acc: 1
  };

  const $ = (s, p=document)=>p.querySelector(s);
  const $$ = (s, p=document)=>[...p.querySelectorAll(s)];
  const logEl = $("#diag");
  const stage = $("#stage");
  const imgEl = $("#src");
  const cFace = $("#cFace");
  const cPose = $("#cPose");
  const cSeg  = $("#cSeg");
  const gInit = $("#gInit"), gRun=$("#gRun"), gFps=$("#gFps");

  const NEGATIVE = "lowres, bad anatomy, extra limbs, deformed hands, oversharpen, cartoonish, unrealistic skin, fused features, duplicate face";

  function log(msg, cls=""){ 
    const t = `[${new Date().toLocaleTimeString()}] ${msg}`;
    logEl.textContent += (logEl.textContent ? "\n" : "") + t;
    if(cls==="warn" || cls==="bad" || cls==="ok"){ /* reserved for styling if needed */ }
    logEl.scrollTop = logEl.scrollHeight;
  }

  /* =========================
     UTIL — EXIF normalize (no dep)
     ========================= */
  async function normalizeImage(fileOrUrl){
    // load into ImageBitmap via createImageBitmap for speed; EXIF orientation is not auto-applied for files.
    let src;
    if (typeof fileOrUrl === "string") {
      src = fileOrUrl;
    } else {
      src = URL.createObjectURL(fileOrUrl);
    }
    return new Promise(async (res, rej)=>{
      const img = new Image();
      img.onload = async ()=>{
        // Draw straight onto canvas — modern browsers already apply correct orientation for Image() of blob URLs.
        // For absolute control, we could parse EXIF and rotate — omitted for M1 to keep zero-deps.
        const off = new OffscreenCanvas ? new OffscreenCanvas(img.naturalWidth, img.naturalHeight) : document.createElement("canvas");
        off.width = img.naturalWidth; off.height = img.naturalHeight;
        const ctx = off.getContext("2d");
        ctx.drawImage(img, 0, 0);
        if (typeof fileOrUrl !== "string") URL.revokeObjectURL(src);
        if (off.convertToBlob){
          const blob = await off.convertToBlob();
          const bmp = await createImageBitmap(blob);
          res({blob, bmp, width: img.naturalWidth, height: img.naturalHeight});
        } else {
          off.toBlob(async (blob)=>{
            const bmp = await createImageBitmap(blob);
            res({blob, bmp, width: img.naturalWidth, height: img.naturalHeight});
          });
        }
      };
      img.onerror = (e)=> rej(e);
      img.src = src;
    });
  }

  /* =========================
     DPR + CANVAS SIZING
     ========================= */
  function sizeCanvases(){
    const rect = stage.getBoundingClientRect();
    const dpr = st.dpr = Math.max(1, window.devicePixelRatio || 1);
    for (const cv of [cFace, cPose, cSeg]){
      cv.width = Math.max(2, Math.floor(rect.width * dpr));
      cv.height= Math.max(2, Math.floor(rect.height* dpr));
      const ctx = cv.getContext("2d");
      ctx.setTransform(dpr,0,0,dpr,0,0); // crisp lines on HiDPI
      ctx.clearRect(0,0,rect.width,rect.height);
    }
  }
  window.addEventListener("resize", ()=>{ sizeCanvases(); if (st.results) drawAll(st.results,true); });

  /* =========================
     SELF-TEST (probes + init choice)
     ========================= */
  async function probe(url){
    try{
      const r = await fetch(url, {method:"HEAD", cache:"no-store"});
      if (!r.ok) return {ok:false, status:r.status};
      const len = r.headers.get("content-length");
      return {ok:true, status:r.status, len: len? parseInt(len):null};
    }catch(e){ return {ok:false, err:String(e)} }
  }

  async function selfTest(){
    log("Self-Test: probing local assets…");
    const rows = [];
    async function pushRow(label, url){
      const p = await probe(url);
      rows.push([label, url, p]);
    }
    await pushRow("MP script", ASSETS.mediapipe.script);
    await pushRow("MP wasm dir", ASSETS.mediapipe.wasmDir);
    await pushRow("MP face task", ASSETS.mediapipe.face);
    await pushRow("MP pose task", ASSETS.mediapipe.pose);
    await pushRow("MP seg tflite", ASSETS.mediapipe.seg);
    await pushRow("Human script", ASSETS.human.script);
    await pushRow("Human models dir", ASSETS.human.modelsDir);
    await pushRow("face-api", ASSETS.minimal.faceApi);
    await pushRow("face-api weights dir", ASSETS.minimal.weightsDir);
    await pushRow("MoveNet json", ASSETS.minimal.movenet);

    // Decide engine
    const mpOk = rows.slice(0,5).every(r=>r[2]?.ok);
    const humanOk = rows[5][2]?.ok; // script
    const minOk = rows[8][2]?.ok && rows[9][2]?.ok && rows[7][2]?.ok;

    st.enginesAvailable = [
      mpOk ? "mediapipe" : null,
      humanOk ? "human" : null,
      minOk ? "minimal" : null
    ].filter(Boolean);

    const prefer = ["mediapipe","human","minimal"];
    st.engine = st.enginesAvailable.find(e=>prefer.includes(e)) || "none";
    $("#engineName").textContent = st.engine;

    // Render matrix
    const lines = ["ASSET MATRIX:"];
    for (const [label,url,p] of rows){
      const stat = p.ok ? "✅" : "❌";
      const extra = p.ok ? (p.len? ` (${p.len} bytes)` : "") : (p.status? ` (HTTP ${p.status})` : (p.err? ` (${p.err})` : ""));
      lines.push(`${stat} ${label} — ${url}${extra}`);
    }
    lines.push(`Engine choice: ${st.engine} (available: ${st.enginesAvailable.join(", ")||"none"})`);
    log(lines.join("\n"));
  }

  /* =========================
     ENGINE LOADERS (scaffold)
     ========================= */
  function loadScriptOnce(src, attrs={}){
    return new Promise((res,rej)=>{
      if (document.querySelector(`script[data-src="${src}"]`)) return res();
      const s = document.createElement("script");
      s.dataset.src = src;
      for (const k in attrs) s.setAttribute(k, attrs[k]);
      s.onload = ()=>res();
      s.onerror = e=>rej(new Error("Failed to load "+src));
      s.src = src;
      document.head.appendChild(s);
    });
  }

  async function initEngine(){
    const t0 = performance.now();
    try{
      if (st.engine === "mediapipe"){
        await loadScriptOnce(ASSETS.mediapipe.script);
        // mediapipe tasks expect base path for wasm — we hint via global if needed
        self.Module = self.Module || {};
        self.Module.locateFile = (file)=> ASSETS.mediapipe.wasmDir + file;
        // Lazy: create handles when analyzing to avoid blocking init
        st.timings.initMs = Math.round(performance.now()-t0);
        log("MediaPipe ready (lazy create at analyze).");
        return true;
      }
      if (st.engine === "human"){
        await loadScriptOnce(ASSETS.human.script);
        if (!self.Human) throw new Error("Human not found after load");
        st.human = new self.Human({
          backend: "webgl",
          async: true,
          modelBasePath: ASSETS.human.modelsDir || undefined,
          face:{ enabled:true, mesh:{enabled:true}, iris:{enabled:true}},
          body:{ enabled:true, modelType:"movenet-lightning" },
          segmentation:{enabled:true},
          object:{ enabled:false }, // toggle per checkbox
          filter:{ enabled:false }
        });
        await st.human.load();
        st.timings.initMs = Math.round(performance.now()-t0);
        log(`Human ready. Models loaded.`);
        return true;
      }
      if (st.engine === "minimal"){
        await loadScriptOnce(ASSETS.minimal.faceApi);
        if (!self.faceapi) throw new Error("face-api not present");
        await self.faceapi.nets.tinyFaceDetector.loadFromUri(ASSETS.minimal.weightsDir);
        await self.faceapi.nets.faceLandmark68Net.loadFromUri(ASSETS.minimal.weightsDir);
        // MoveNet lite loading left as exercise; we’ll only do face in minimal for M1.
        st.timings.initMs = Math.round(performance.now()-t0);
        log("Minimal engine ready (face-api 68pt only).");
        return true;
      }
      log("No engine selected or available.","warn");
      return false;
    } catch(e){
      log("Engine init error: "+e.message);
      st.engine = "none";
      $("#engineName").textContent = st.engine;
      return false;
    } finally {
      gInit.style.width = Math.min(100, st.timings.initMs/1500*100).toFixed(1)+"%";
    }
  }

  /* =========================
     ANALYZE (unified results)
     ========================= */
  async function analyze(){
    if (!st.bmp) { log("No image loaded. Use Choose or Demo.", "warn"); return; }
    if (st.engine==="none") { log("No engine available. Run Self-Test and place models.", "warn"); return; }
    const rect = stage.getBoundingClientRect();
    sizeCanvases();
    clearOverlays();

    const t0 = performance.now();
    let res = { face:null, pose:null, seg:null, objects:[], width: st.bmp.width, height: st.bmp.height };

    try{
      if (st.engine==="mediapipe"){
        // Lazy import factory APIs from tasks-vision global if available
        // NOTE: This block is a scaffold; wire exact APIs once your tasks-vision.js is confirmed.
        // For M1 we simulate results if tasks aren’t present to allow overlay visual verification.
        if (!self.FaceLandmarker || !self.PoseLandmarker || !self.ImageSegmenter){
          log("MediaPipe factories not found — simulate overlay to verify drawing. Place *.task and tasks-vision.js for real inference.","warn");
          res = synthesizeResults(rect);
        } else {
          // Example pseudo-code; adjust to your exact Tasks Vision API surface.
          // const face = await runMPFace(st.bmp); const pose = await runMPPose(st.bmp); const seg = await runMPSeg(st.bmp);
          // res.face = face; res.pose = pose; res.seg = seg;
          res = synthesizeResults(rect); // placeholder until wired — keeps UX working
        }
      } else if (st.engine==="human"){
        // Human end-to-end
        const {human} = st;
        const analyzeRes = await human.detect(st.bmp, {skipPostprocess:false});
        // Map to unified:
        if (analyzeRes?.face?.length){
          const f = analyzeRes.face[0];
          res.face = {
            points: f.mesh || [], // array of [x,y,z?]
            score: f.score || f.faceScore || 0.9
          };
        }
        if (analyzeRes?.body?.length){
          const b = analyzeRes.body[0];
          res.pose = {
            keypoints: (b.keypoints || []).map(k=>({x:k.position?.x||k.x, y:k.position?.y||k.y, name:k.part||k.name||""})),
            score: b.score || 0.9
          };
        }
        if (analyzeRes?.segmentation?.mask){
          res.seg = analyzeRes.segmentation.mask; // HTMLCanvasElement/ImageBitmap
        }
        if ($("#tgObj").checked && analyzeRes?.object?.length){
          res.objects = analyzeRes.object.map(o=>({x:o.box?.x, y:o.box?.y, w:o.box?.width, h:o.box?.height, label:o.label, score:o.score}));
        }
      } else if (st.engine==="minimal"){
        // face-api only (68pt)
        const det = await faceapi.detectSingleFace(imgEl, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
        if (det?.landmarks){
          const pts = det.landmarks.positions.map(p=>[p.x, p.y, 0]);
          res.face = { points: pts, score: 0.8 };
        } else {
          res = synthesizeResults(rect);
          log("Minimal: no face detected. Showing synthetic overlay to verify visuals.","warn");
        }
      }
    } catch(e){
      log("Analyze error: "+e.message);
      res = synthesizeResults(rect);
    }

    st.timings.analyzeMs = Math.round(performance.now() - t0);
    gRun.style.width = Math.min(100, st.timings.analyzeMs/1200*100).toFixed(1)+"%";

    // Compute metrics + prompt/JSON
    const metrics = computeMetrics(res);
    const prompt = buildPrompt(metrics, st.acc);
    const json = buildJSON(metrics, res);

    $("#promptOut").value = prompt + "\n\nNegative:\n" + NEGATIVE;
    $("#jsonOut").value = JSON.stringify(json, null, 2);

    // Draw overlays with phase animation
    await drawPhased(res);

    log(`Analyze done in ${st.timings.analyzeMs} ms using ${st.engine}. Face:${!!res.face} Pose:${!!res.pose} Seg:${!!res.seg}`);
  }

  /* =========================
     SYNTHETIC RESULTS (visual verify)
     ========================= */
  function synthesizeResults(rect){
    const W = rect.width, H = rect.height;
    // Simple ellipse "face" + a few keypoints and one bounding box object
    const pts = [];
    for (let i=0;i<60;i++){
      const a = (i/60)*Math.PI*2;
      pts.push([W*0.5 + Math.cos(a)*W*0.18, H*0.42 + Math.sin(a)*H*0.22, 0]);
    }
    const kps = [
      {x:W*0.5, y:H*0.20, name:"nose"},
      {x:W*0.45, y:H*0.42, name:"left_eye"},
      {x:W*0.55, y:H*0.42, name:"right_eye"},
      {x:W*0.50, y:H*0.70, name:"hips"},
      {x:W*0.50, y:H*0.55, name:"neck"},
    ];
    return {
      face: { points: pts, score: 0.99 },
      pose: { keypoints: kps, score: 0.8 },
      seg: null,
      objects: [{x:W*0.12, y:H*0.12, w:W*0.2, h:H*0.18, label:"object", score:0.66}],
      width: W, height: H
    };
  }

  /* =========================
     METRICS + PROMPT + JSON
     ========================= */
  function computeMetrics(res){
    const rect = stage.getBoundingClientRect();
    const W = rect.width, H = rect.height;
    // Eye tilt: if we have eye keypoints, otherwise estimate from synthetic
    let eyeTilt = 0;
    if (res.pose?.keypoints?.length){
      const le = res.pose.keypoints.find(k=>/left_eye/i.test(k.name)) || {x:W*.45,y:H*.42};
      const re = res.pose.keypoints.find(k=>/right_eye/i.test(k.name))|| {x:W*.55,y:H*.42};
      eyeTilt = Math.atan2((re.y - le.y), (re.x - le.x)) * 180/Math.PI;
    }
    const faceShape = "oval"; // M1 heuristic can be refined later
    const hair="dark brown", eyes="hazel", skin="light"; // M1 palette stubs
    // Body scanlines (bust/waist/hips) — M1: rough proportions
    const bust=[W*.35, W*.65], waist=[W*.40, W*.60], hips=[W*.33, W*.67];
    const shoulderSpan = (W*.62 - W*.38);
    const cameraAngle = "slightly high angle";
    const lighting = "soft diffused light";
    const bg = "neutral backdrop";

    return {
      image:{ width:W, height:H, dpr: st.dpr },
      face:{ eyeTilt, shape:faceShape, palette:{hair,eyes,skin}, points:res.face?.points?.length||0 },
      body:{
        shoulderSpanPx: shoulderSpan,
        shoulderSpanPct: +(shoulderSpan/W*100).toFixed(1),
        bwh:{ bust, waist, hips },
        ratios:{ waist_to_hips: +( (waist[1]-waist[0])/(hips[1]-hips[0]) ).toFixed(2),
                 shoulder_to_waist: +((shoulderSpan)/(waist[1]-waist[0])).toFixed(2) }
      },
      scene:{ cameraAngle, lighting, bg },
      raw: res
    };
  }

  function buildPrompt(m, acc=1){
    const roundTo = acc===0? 5 : acc===1? 2 : 1;
    const tilt = Math.round(m.face.eyeTilt/roundTo)*roundTo;
    const extras = acc===2 ? ", fine micro-texture" : (acc===0? "" : "");
    return `portrait photo, ${m.face.shape} face, eye tilt ${tilt}°, ${m.face.palette.hair} hair, ${m.face.palette.eyes} eyes, ${m.face.palette.skin} skin, ${m.scene.cameraAngle}, ${m.scene.lighting}, ${m.scene.bg}, photorealistic, sharp micro-detail, minimal distortion${extras}`;
  }

  function buildJSON(m, res){
    return {
      version: 4,
      engine: { selected: st.engine, available: st.enginesAvailable, timings: st.timings },
      image: { width:m.image.width, height:m.image.height, dpr:m.image.dpr, orientation:"exif-fixed" },
      overlays: { face: $("#tgFace").checked, pose: $("#tgPose").checked, segments: $("#tgSeg").checked, objects: $("#tgObj").checked },
      face:{
        eye_tilt_deg: +m.face.eyeTilt.toFixed(1),
        shape: m.face.shape,
        palette: m.face.palette,
        landmark_stats: { points: m.face.points, confidence: 0.0 }
      },
      body:{
        shoulder_span_px: Math.round(m.body.shoulderSpanPx),
        shoulder_span_pct: m.body.shoulderSpanPct,
        bwh_scanlines: { bust: m.body.bwh.bust, waist:m.body.bwh.waist, hips:m.body.bwh.hips },
        ratios: m.body.ratios
      },
      scene:{
        camera_angle: m.scene.cameraAngle,
        lighting: m.scene.lighting,
        bg_tag: m.scene.bg
      },
      prompts:{
        replica_sfw: $("#promptOut").value.split("\n\nNegative:")[0] || "",
        negative: NEGATIVE
      },
      cloud:{ clip_hint: null, objects: res.objects||[] },
      diag:{ fps: st.timings.fps, errors: [], log: logEl.textContent.split("\n").slice(-50) }
    };
  }

  /* =========================
     DRAWING UTILS
     ========================= */
  function clearOverlays(){
    const rect = stage.getBoundingClientRect();
    for (const cv of [cFace,cPose,cSeg]){
      const ctx = cv.getContext("2d");
      ctx.clearRect(0,0,rect.width,rect.height);
    }
  }
  function drawAll(res, instant=false){ drawFace(res,instant); drawPose(res,instant); drawSeg(res,instant); drawObjects(res,instant); }
  function drawFace(res, instant=false){
    if (!$("#tgFace").checked) return;
    if (!res.face?.points?.length) return;
    const ctx = cFace.getContext("2d");
    const rect = stage.getBoundingClientRect();
    const pts = res.face.points;
    const alpha = instant? 1 : 0.9;
    ctx.save();
    ctx.clearRect(0,0,rect.width,rect.height);
    // Glow halo
    ctx.globalAlpha = 0.25*alpha;
    ctx.strokeStyle = "rgba(14,255,255,.4)";
    ctx.lineWidth = 10;
    outline(ctx, pts);
    // Dots + fine outline
    ctx.globalAlpha = 1;
    ctx.lineWidth = 1.2;
    ctx.strokeStyle = "rgba(14,255,255,.9)";
    outline(ctx, pts);
    // Sampled neon dots
    ctx.fillStyle = "rgba(14,255,255,.9)";
    const step = Math.max(1, Math.floor(4/(st.detail||1)));
    for (let i=0;i<pts.length;i+=step){
      const [x,y] = pts[i];
      ctx.beginPath(); ctx.arc(x,y,1.6,0,Math.PI*2); ctx.fill();
    }
    // Eye tilt label
    ctx.fillStyle = "rgba(223,247,255,.96)";
    ctx.font = "12px ui-monospace,monospace";
    ctx.fillText("FACE", 8, 16);
    ctx.restore();
  }
  function outline(ctx, pts){
    ctx.beginPath();
    for (let i=0;i<pts.length;i++){
      const [x,y] = pts[i];
      if (i===0) ctx.moveTo(x,y); else ctx.lineTo(x,y);
    }
    ctx.closePath(); ctx.stroke();
  }
  function drawPose(res, instant=false){
    if (!$("#tgPose").checked) return;
    if (!res.pose?.keypoints?.length) return;
    const ctx = cPose.getContext("2d");
    const rect = stage.getBoundingClientRect();
    ctx.clearRect(0,0,rect.width,rect.height);
    ctx.strokeStyle = "rgba(255,75,214,.9)";
    ctx.lineWidth = 2;
    const k = res.pose.keypoints;
    // Draw simple bone connections (subset)
    function kp(name){ return k.find(p=>p.name===name); }
    const pairs = [
      ["neck","left_eye"],["neck","right_eye"],["neck","hips"]
    ];
    for (const [a,b] of pairs){
      const A = kp(a), B = kp(b); if (A&&B){ ctx.beginPath(); ctx.moveTo(A.x,A.y); ctx.lineTo(B.x,B.y); ctx.stroke(); }
    }
    // Points
    ctx.fillStyle = "rgba(255,75,214,.95)";
    for (const p of k){ ctx.beginPath(); ctx.arc(p.x,p.y,3,0,Math.PI*2); ctx.fill(); }
    // Labels
    ctx.fillStyle = "rgba(223,247,255,.96)"; ctx.font="12px ui-monospace,monospace";
    ctx.fillText("POSE", 8, 32);
  }
  function drawSeg(res, instant=false){
    if (!$("#tgSeg").checked) return;
    const ctx = cSeg.getContext("2d");
    const rect = stage.getBoundingClientRect();
    ctx.clearRect(0,0,rect.width,rect.height);
    if (res.seg){
      // If we have an ImageBitmap/canvas mask, draw tinted
      try{
        ctx.globalAlpha = 0.45;
        ctx.drawImage(res.seg, 0,0, rect.width, rect.height);
        ctx.globalCompositeOperation = "source-atop";
        ctx.fillStyle = "rgba(180,255,75,.35)";
        ctx.fillRect(0,0,rect.width,rect.height);
        ctx.globalCompositeOperation = "source-over";
      }catch(e){}
    } else {
      // Synthetic scanline reveal
      const tiles = 8;
      for (let i=0;i<tiles;i++){
        const y = (i/tiles)*rect.height;
        ctx.fillStyle = "rgba(180,255,75,.06)";
        ctx.fillRect(0,y, rect.width, rect.height/tiles - 2);
      }
    }
    // Gauges B/W/H
    ctx.fillStyle = "rgba(180,255,75,.8)";
    const yBust = rect.height*0.42, yWaist=rect.height*0.55, yHips=rect.height*0.70;
    ctx.fillRect(rect.width*0.35, yBust, rect.width*(0.30), 2);
    ctx.fillRect(rect.width*0.40, yWaist, rect.width*(0.20), 2);
    ctx.fillRect(rect.width*0.33, yHips, rect.width*(0.34), 2);
    ctx.fillStyle = "rgba(223,247,255,.96)"; ctx.font="12px ui-monospace,monospace";
    ctx.fillText("SEGMENTS", 8, 48);
  }
  function drawObjects(res, instant=false){
    if (!$("#tgObj").checked) return;
    if (!res.objects?.length) return;
    const ctx = cSeg.getContext("2d"); // draw on top of seg layer
    const rect = stage.getBoundingClientRect();
    for (const o of res.objects){
      ctx.save();
      ctx.setLineDash([6,6]);
      ctx.strokeStyle = "rgba(255,75,214,.9)";
      ctx.lineWidth = 2;
      ctx.strokeRect(o.x, o.y, o.w, o.h);
      ctx.fillStyle = "rgba(14,255,255,.95)";
      ctx.font = "12px ui-monospace,monospace";
      const label = `${o.label||"object"}:${(o.score??0).toFixed(2)}`;
      ctx.fillText(label, o.x+4, o.y-6);
      ctx.restore();
    }
  }

  async function drawPhased(res){
    const rect = stage.getBoundingClientRect();
    const start = performance.now();
    const frames = [];
    const addFrame = (cb)=> frames.push(cb);
    if ($("#tgFace").checked) addFrame(()=>drawFace(res));
    if ($("#tgPose").checked) addFrame(()=>drawPose(res));
    if ($("#tgSeg").checked)  addFrame(()=>drawSeg(res));
    if ($("#tgObj").checked)  addFrame(()=>drawObjects(res));

    let i=0, last = performance.now(), count=0;
    function step(){
      if (i<frames.length){ frames[i++](); }
      count++;
      const now = performance.now();
      const dt = now - last; last = now;
      st.timings.fps = Math.round(1000/(dt||16));
      gFps.style.width = Math.min(100, st.timings.fps/60*100).toFixed(1)+"%";
      if (i<frames.length) requestAnimationFrame(step);
    }
    requestAnimationFrame(step);
  }

  /* =========================
     UI WIRING
     ========================= */
  $("#choose").addEventListener("click", ()=> $("#file").click());
  $("#demo").addEventListener("click", async ()=>{
    try{
      const n = await normalizeImage(ASSETS.demo);
      st.bmp = n.bmp;
      imgEl.src = URL.createObjectURL(await (n.blob));
      setTimeout(sizeCanvases, 0);
      log("Demo image loaded.");
    }catch(e){ log("Demo failed: "+e.message); }
  });
  $("#file").addEventListener("change", async (e)=>{
    const f = e.target.files?.[0]; if (!f) return;
    const n = await normalizeImage(f);
    st.bmp = n.bmp;
    imgEl.src = URL.createObjectURL(n.blob);
    setTimeout(sizeCanvases, 0);
    log("Image loaded.");
  });

  $("#selftest").addEventListener("click", async ()=>{
    await selfTest();
    await initEngine();
  });

  $("#analyze").addEventListener("click", async ()=>{
    if (st.engine==="none"){ await selfTest(); await initEngine(); }
    await analyze();
  });

  $("#clear").addEventListener("click", ()=>{
    clearOverlays(); log("Overlays cleared.");
  });

  $("#detail").addEventListener("input", e=>{ st.detail = +e.target.value; $("#detailVal").textContent = st.detail.toFixed(1); if (st.results) drawAll(st.results,true); });
  $("#acc").addEventListener("input", e=>{ st.acc = +e.target.value; $("#accVal").textContent = {0:"0 (tight)",1:"1 (medium)",2:"2 (rich)"}[st.acc]; });

  $("#tgFace").addEventListener("change", ()=> st.toggles.face = $("#tgFace").checked);
  $("#tgPose").addEventListener("change", ()=> st.toggles.pose = $("#tgPose").checked);
  $("#tgSeg").addEventListener("change",  ()=> st.toggles.seg  = $("#tgSeg").checked);
  $("#tgObj").addEventListener("change",  ()=> st.toggles.obj  = $("#tgObj").checked);

  // Tabs
  $$(".tab").forEach(t=>{
    t.addEventListener("click", ()=>{
      $$(".tab").forEach(x=>x.classList.remove("active"));
      t.classList.add("active");
      const name = t.dataset.tab;
      $$(".panel").forEach(p=>p.classList.remove("active"));
      $("#panel-"+name).classList.add("active");
    });
  });

  // Copy / Download
  $("#copyPrompt").addEventListener("click", async ()=>{
    try{ await navigator.clipboard.writeText($("#promptOut").value); log("Prompt copied."); }catch(e){ log("Clipboard failed: "+e.message); }
  });
  $("#copyNeg").addEventListener("click", async ()=>{
    try{ await navigator.clipboard.writeText(NEGATIVE); log("Negative copied."); }catch(e){ log("Clipboard failed: "+e.message); }
  });
  $("#downloadJson").addEventListener("click", ()=>{
    const blob = new Blob([$("#jsonOut").value||"{}"], {type:"application/json"});
    const a = document.createElement("a");
    a.href = URL.createObjectURL(blob);
    a.download = "imageintel_v4.json";
    a.click();
    URL.revokeObjectURL(a.href);
  });

  // Initial sizing
  sizeCanvases();
  log("Ready. Load an image or click Use Demo Photo, then Self-Test → Preview Overlay.");
  </script>
</body>
</html>
