<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Face Mesh Test Overlay</title>
  <style>
    body { margin:0; background:#000; color:#fff; text-align:center; }
    #stage { position: relative; display:inline-block; }
    #stage img { max-width:100%; }
    canvas { position:absolute; top:0; left:0; pointer-events:none; }
  </style>
</head>
<body>
  <h3>Face Mesh Test</h3>
  <input type="file" id="fileIn" accept="image/*"/>
  <button id="btnDemo">Demo</button>
  <div id="stage">
    <img id="imgEl" />
    <canvas id="cv"></canvas>
  </div>
  <pre id="log"></pre>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.19.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@1.0.5/dist/face-landmarks-detection.min.js"></script>
  <script>
    (async ()=>{
      const imgEl = document.getElementById('imgEl');
      const cv = document.getElementById('cv');
      const logEl = document.getElementById('log');

      function log(m){ logEl.textContent = m + "\n" + logEl.textContent; }

      await tf.setBackend('webgl');
      await tf.ready();
      log("TFJS backend: " + tf.getBackend());

      const model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
      );
      log("FaceMesh model loaded");

      function fitCanvas(){
        const r = imgEl.getBoundingClientRect();
        cv.style.width = r.width + "px";
        cv.style.height = r.height + "px";
        cv.width = r.width * window.devicePixelRatio;
        cv.height = r.height * window.devicePixelRatio;
        const ctx = cv.getContext('2d');
        ctx.setTransform(window.devicePixelRatio,0,0,window.devicePixelRatio,0,0);
      }

      document.getElementById('fileIn').onchange = e => {
        const f = e.target.files[0];
        if (!f) return;
        const url = URL.createObjectURL(f);
        imgEl.onload = fitCanvas;
        imgEl.src = url;
      };

      document.getElementById('btnDemo').onclick = async ()=>{
        const resp = await fetch('https://images.unsplash.com/photo-1529626455594-4ff0802cfb7e?w=800');
        const blob = await resp.blob();
        const url = URL.createObjectURL(blob);
        imgEl.onload = fitCanvas;
        imgEl.src = url;
      };

      // analyze & draw
      async function analyze(){
        if (!imgEl.naturalWidth) { log("Load image first"); return; }
        fitCanvas();
        const off = document.createElement('canvas');
        off.width = imgEl.naturalWidth;
        off.height = imgEl.naturalHeight;
        off.getContext('2d').drawImage(imgEl, 0, 0);

        const faces = await model.estimateFaces({input: off, returnTensors:false});
        log("faces: " + faces.length);
        const ctx = cv.getContext('2d');
        ctx.clearRect(0,0,cv.width,cv.height);

        faces.forEach(f=>{
          f.scaledMesh.forEach(pt=>{
            const [x,y,z] = pt;
            ctx.beginPath();
            ctx.arc(x, y, 1.5, 0, Math.PI*2);
            ctx.fillStyle = "cyan";
            ctx.fill();
          });
        });
      }

      // auto-run analyze after load
      imgEl.onload = ()=>{
        fitCanvas();
        analyze();
      };
    })();
  </script>
</body>
</html>
