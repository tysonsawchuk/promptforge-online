<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta http-equiv="Cross-Origin-Opener-Policy" content="same-origin">
<meta http-equiv="Cross-Origin-Embedder-Policy" content="require-corp">
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>ImageIntel Pro Visor — Local-Only (No Network, WebGL TFJS)</title>
<style>
  :root{--bg:#0b0f14;--panel:#121822;--ink:#e9fbff;--mut:#9fb3c0;--aqua:#64f2e3;--green:#52ffa8;--gold:#ffd166;--red:#ff6b6b}
  html,body{margin:0;background:var(--bg);color:var(--ink);font-family:Inter,system-ui,Segoe UI,Roboto,Arial,sans-serif}
  .wrap{max-width:1200px;margin:24px auto;padding:0 16px}
  .grid{display:grid;grid-template-columns:1.2fr .8fr;gap:16px}
  @media(max-width:1100px){.grid{grid-template-columns:1fr}}
  .card{background:var(--panel);border:1px solid #1e2835;border-radius:14px;box-shadow:0 8px 24px #0005;overflow:hidden}
  .card h2{margin:0;padding:10px 12px;border-bottom:1px solid #1b2531;background:#0e141c;font-size:1rem}
  .pad{padding:12px}
  .row{display:flex;gap:8px;flex-wrap:wrap;align-items:center}
  .btn{background:#182130;border:1px solid #2a3445;color:var(--aqua);padding:8px 12px;border-radius:9px;font-weight:700;cursor:pointer}
  .btn:hover{border-color:#3c4d64;background:#1a2738}
  .input{background:#0f1621;border:1px solid #233044;color:#bfefff;border-radius:8px;padding:8px 10px;min-width:260px;width:100%}
  .mini{font-size:.9rem;color:var(--mut)}
  .pill{display:inline-block;padding:3px 8px;border-radius:999px;background:#0e1722;border:1px solid #243246;color:#9ad7ff;font-size:.8rem}
  .stage{position:relative;display:inline-block;max-width:100%}
  .stage img{display:block;max-width:100%;height:auto;border-radius:10px;border:1px solid #1d2632}
  canvas.layer{position:absolute;left:0;top:0;pointer-events:none}
  .diag{font-family:ui-monospace,Consolas,Menlo,monospace;font-size:.9rem;line-height:1.35;white-space:pre-wrap}
  .good{color:var(--green)} .warn{color:var(--gold)} .bad{color:var(--red)} .mut{color:#9fb3c0}
</style>
</head>
<body>
<div class="wrap">
  <h1>ImageIntel Pro Visor — Local-Only (WebGL TFJS)</h1>
  <p class="mini">No external network calls. All libraries and models must be served from this origin under <code>/vendor/tfjs</code> and <code>/models</code>.</p>

  <div class="grid">
    <div class="card">
      <h2>Stage</h2>
      <div class="pad">
        <div class="row">
          <input type="file" id="fileInput" accept="image/*" class="input" style="max-width:360px"/>
          <button class="btn" id="btnFit">Fit Canvases</button>
          <button class="btn" id="btnSelfTest">Self-Test</button>
        </div>
        <div class="mini" id="imgMeta">No image loaded.</div>
        <div style="height:10px"></div>
        <div id="stage" class="stage">
          <img id="imgEl" alt="preview"/>
          <canvas id="cvFace" class="layer"></canvas>
          <canvas id="cvPose" class="layer"></canvas>
          <canvas id="cvSeg"  class="layer"></canvas>
        </div>
      </div>
    </div>

    <div class="card">
      <h2>Controls</h2>
      <div class="pad">
        <div class="row">
          <span class="pill">Engine: <span id="engine">uninitialized</span></span>
          <span class="pill">DPR: <span id="kDpr">–</span></span>
          <span class="pill">Image: <span id="kImg">–</span></span>
          <span class="pill">Canvas: <span id="kCan">–</span></span>
        </div>
        <div class="row" style="margin-top:6px">
          <button class="btn" id="btnInit">Init Engine</button>
          <button class="btn" id="btnAnalyze">Analyze (A→B→C)</button>
          <button class="btn" id="btnClear">Clear Overlays</button>
        </div>
        <div class="mini" style="margin-top:10px">
          If anything fails, see Diagnostics below — it will list the exact missing file.
        </div>
      </div>
    </div>
  </div>

  <div class="card" style="margin-top:16px">
    <h2>Diagnostics</h2>
    <div class="pad"><div id="log" class="diag"></div></div>
  </div>
</div>

<!-- LOCAL scripts only (no CDNs). Place these files on your server exactly at these paths. -->
<script src="/vendor/tfjs/tf.min.js"></script>
<script src="/vendor/tfjs/face-landmarks-detection.min.js"></script>
<script src="/vendor/tfjs/pose-detection.min.js"></script>
<script src="/vendor/tfjs/body-segmentation.min.js"></script>

<script>
(function(){
  const $=s=>document.querySelector(s);
  const logEl=$('#log'); const engineEl=$('#engine');
  const log=(m,c='mut')=>{const d=document.createElement('div'); d.className=c; d.textContent=m; logEl.prepend(d);};

  const imgEl=$('#imgEl'); const cvFace=$('#cvFace'), cvPose=$('#cvPose'), cvSeg=$('#cvSeg');
  const DPR=Math.max(1,window.devicePixelRatio||1); $('#kDpr').textContent=DPR.toFixed(2);

  let models={face:null, pose:null, segm:null}; let engine='tfjs';

  // Utility: HEAD/Range probe to verify local files exist (served correctly)
  async function exists(url){ try{ const r=await fetch(url,{headers:{'Range':'bytes=0-16'}}); return r.ok||r.status===206; }catch(e){ return false; } }

  async function selfTest(){
    log('--- Self-Test ---','mut');
    // library presence
    if (!window.tf) { log('Missing /vendor/tfjs/tf.min.js','bad'); return; }
    log('tfjs loaded: '+tf.version_core,'good');
    const libs = [
      ['/vendor/tfjs/face-landmarks-detection.min.js', !!window.faceLandmarksDetection],
      ['/vendor/tfjs/pose-detection.min.js', !!window.poseDetection],
      ['/vendor/tfjs/body-segmentation.min.js', !!window.bodySegmentation],
    ];
    for (const [u,ok] of libs){ log((ok?'OK  ':'X   ')+u, ok?'good':'bad'); if(!ok) return; }

    // model files exist?
    const must=[
      '/models/facemesh/model.json',
      '/models/facemesh_iris/model.json',
      '/models/movenet_lightning/model.json',
      '/models/selfie_segmentation/model.json'
    ];
    for (const u of must){ const ok=await exists(u); log((ok?'OK  ':'X   ')+u, ok?'good':'bad'); if(!ok) log(' → Place model.json + shards at '+u.replace(/model\.json$/,''),'warn'); }

    log('Backend: trying WebGL…','mut');
    try{ await tf.setBackend('webgl'); await tf.ready(); log('tf.getBackend(): '+tf.getBackend(),'good'); }catch(e){ log('WebGL backend failed. Enable hardware acceleration / allow WebGL.','bad'); }
    log('---------------','mut');
  }

  function fitCanvases(){
    if (!imgEl.naturalWidth){ log('Load an image first','warn'); return; }
    const rect = imgEl.getBoundingClientRect();
    [cvFace,cvPose,cvSeg].forEach(cv=>{
      const ctx=cv.getContext('2d');
      cv.style.width=rect.width+'px'; cv.style.height=rect.height+'px';
      cv.width=Math.max(1,Math.round(rect.width*DPR)); cv.height=Math.max(1,Math.round(rect.height*DPR));
      ctx.setTransform(DPR,0,0,DPR,0,0); ctx.clearRect(0,0,cv.width,cv.height);
    });
    $('#kImg').textContent=imgEl.naturalWidth+'×'+imgEl.naturalHeight;
    $('#kCan').textContent=Math.round(cvFace.width/DPR)+'×'+Math.round(cvFace.height/DPR);
  }

  function imageToCanvas(){
    const r=imgEl.getBoundingClientRect(); const c=document.createElement('canvas');
    c.width=Math.max(1,Math.round(r.width)); c.height=Math.max(1,Math.round(r.height));
    c.getContext('2d').drawImage(imgEl,0,0,c.width,c.height);
    return c;
  }

  async function initEngine(){
    try{
      // Load models from local paths explicitly (no remote).
      await tf.setBackend('webgl'); await tf.ready();

      models.face = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
        {
          shouldLoadIrisModel: true,
          maxFaces: 1,
          // Force local URLs:
          modelUrl: '/models/facemesh/model.json',
          irisModelUrl: '/models/facemesh_iris/model.json'
        }
      );

      models.pose = await poseDetection.createDetector(
        poseDetection.SupportedModels.MoveNet,
        {
          modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
          modelUrl: '/models/movenet_lightning/model.json'
        }
      );

      models.segm = await bodySegmentation.createSegmenter(
        bodySegmentation.SupportedModels.MediaPipeSelfieSegmentation,
        {
          runtime: 'tfjs',
          modelType: 'general',
          modelUrl: '/models/selfie_segmentation/model.json'
        }
      );

      engine='tfjs'; engineEl.textContent='TFJS (WebGL, local)';
      log('TFJS models loaded from local paths ✔︎','good');
      return true;
    }catch(e){
      console.error(e);
      log('Init failed — missing model files or blocked WebGL. See Self-Test paths.','bad');
      return false;
    }
  }

  async function analyze(){
    if (!imgEl.naturalWidth){ log('Load an image first','warn'); return; }
    if (!models.face || !models.pose || !models.segm){
      const ok = await initEngine(); if(!ok) return;
    }
    fitCanvases();
    [cvFace,cvPose,cvSeg].forEach(cv=>cv.getContext('2d').clearRect(0,0,cv.width,cv.height));
    const src=imageToCanvas();

    // FACE (468 pts)
    const faces = await models.face.estimateFaces({input:src, returnTensors:false, flipHorizontal:false, predictIrises:true});
    log(`Face: ${faces.length}`, faces.length?'good':'warn');
    const ctxF=cvFace.getContext('2d'); ctxF.lineWidth=1.2; ctxF.strokeStyle='#2bd1ff55';
    faces.forEach(face=>{
      const pts = face.scaledMesh || [];
      for(let i=0;i<pts.length;i++){
        const [x,y]=pts[i]; ctxF.beginPath(); ctxF.arc(x,y,1.2,0,Math.PI*2); ctxF.stroke();
      }
      // rough eye-tilt
      if (face.annotations?.leftEyeUpper0 && face.annotations?.rightEyeUpper0){
        const L=face.annotations.leftEyeUpper0[0], R=face.annotations.rightEyeUpper0.slice(-1)[0];
        const tilt=(Math.atan2((R[1]-L[1]),(R[0]-L[0]))*180/Math.PI).toFixed(1);
        ctxF.save(); ctxF.font='bold 12px ui-monospace'; ctxF.lineWidth=3;
        ctxF.strokeStyle='#061019'; ctxF.fillStyle='#e6f6ff';
        ctxF.strokeText(`eye tilt ${tilt}°`, (L[0]+R[0])/2, (L[1]+R[1])/2 - 12);
        ctxF.fillText(`eye tilt ${tilt}°`,   (L[0]+R[0])/2, (L[1]+R[1])/2 - 12);
        ctxF.restore();
      }
    });

    // POSE (MoveNet)
    const pRes = await models.pose.estimatePoses(src, {flipHorizontal:false});
    log(`Pose: ${pRes.length}`, pRes.length?'good':'warn');
    const ctxP=cvPose.getContext('2d'); ctxP.strokeStyle='#89f'; ctxP.fillStyle='#aaf';
    if (pRes[0]?.keypoints){
      const kp=pRes[0].keypoints;
      const C=(a,b)=>{ if(kp[a]?.score>0.3 && kp[b]?.score>0.3){ ctxP.beginPath(); ctxP.moveTo(kp[a].x,kp[a].y); ctxP.lineTo(kp[b].x,kp[b].y); ctxP.stroke(); } };
      // torso/arms/legs minimal graph
      C(5,7); C(7,9); C(6,8); C(8,10); C(11,13); C(13,15); C(12,14); C(14,16); C(5,6); C(5,11); C(6,12); C(11,12);
      kp.forEach(k=>{ if(k.score>0.3){ ctxP.beginPath(); ctxP.arc(k.x,k.y,2,0,Math.PI*2); ctxP.fill(); } });
    }

    // SEGMENTATION (SelfieSegmentation)
    const seg = await models.segm.segmentPeople(src, {multiSegmentation:false, segmentBodyParts:false});
    const mask = seg?.[0]?.mask;
    log(`Seg: ${mask?'mask ok':'none'}`, mask?'good':'warn');
    if (mask){
      const ctxS=cvSeg.getContext('2d');
      const {width,height,data} = mask; // Uint8ClampedArray alpha
      const id=ctxS.createImageData(width,height);
      for(let i=0;i<width*height;i++){
        const a=data[i];
        id.data[i*4+0]=255; id.data[i*4+1]=120; id.data[i*4+2]=120; id.data[i*4+3]=a?80:0;
      }
      const tmp=document.createElement('canvas'); tmp.width=width; tmp.height=height;
      tmp.getContext('2d').putImageData(id,0,0);
      ctxS.drawImage(tmp,0,0,src.width,src.height);
    }
  }

  // UI
  function loadBlob(blob){
    const url=URL.createObjectURL(blob);
    imgEl.onload=()=>{ URL.revokeObjectURL(url); $('#imgMeta').textContent=`Loaded ${imgEl.naturalWidth}×${imgEl.naturalHeight}`; fitCanvases(); };
    imgEl.src=url;
  }
  $('#fileInput').addEventListener('change', e=>{ const f=e.target.files?.[0]; if(!f) return; loadBlob(f); });
  $('#btnFit').addEventListener('click', fitCanvases);
  $('#btnInit').addEventListener('click', initEngine);
  $('#btnAnalyze').addEventListener('click', analyze);
  $('#btnClear').addEventListener('click', ()=>[cvFace,cvPose,cvSeg].forEach(cv=>cv.getContext('2d').clearRect(0,0,cv.width,cv.height)));
  $('#btnSelfTest').addEventListener('click', selfTest);

  // Hint if opened as file://
  if (location.protocol==='file:'){ log('Run over http:// (localhost) so the image can be drawn to canvas.', 'warn'); }
})();
</script>
</body>
</html>
